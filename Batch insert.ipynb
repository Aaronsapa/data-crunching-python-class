{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch vs. Streamin Processing\n",
    "*[Source](https://thenewstack.io/the-big-data-debate-batch-processing-vs-streaming-processing/)*\n",
    "## Definitions\n",
    "- A batch is a collection of data points that have been grouped together within a specific time interval. Another term often used for this is a window of data. \n",
    "- Streaming processing deals with continuous data and is key to turning big data into fast data. Both models are valuable and each can be used to address different use cases. \n",
    "\n",
    "While the batch processing model requires a set of data collected over time, streaming processing requires data to be fed into an analytics tool, and in real-time. Batch processing is often used when dealing with large volumes of data or data sources from legacy systems, where it’s not feasible to deliver data in streams. Batch data also by definition requires all the data needed for the batch to be loaded to some type of storage, a database or file system to then be processed. \n",
    "\n",
    "Data streams can also be involved in processing large quantities of data, but batch works best when you don’t need real-time analytics. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mining Newsfeed data\n",
    "## 1. API setup\n",
    "1. Create an account at: https://newsapi.org/register\n",
    "2. Save API Key\n",
    "  - Optional: save as environment variable.\n",
    "      - Linux/OS: https://www.digitalocean.com/community/tutorials/how-to-read-and-set-environmental-and-shell-variables-on-linux\n",
    "          - Command Line\n",
    "          - Write file ~/.bashrc\n",
    "              - `NEWS_API_KEY=\"<Your Key>\"`\n",
    "          - run `source ~/.bashrc`\n",
    "      - Windows: http://codevba.com/office/environ.htm#.YAkatZP0lhE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's understand how does the API work. https://newsapi.org/docs/get-started\n",
    "\n",
    "Data example for `sources` endpoint\n",
    "```JSON\n",
    "{\n",
    "    \"status\": \"ok\",\n",
    "    -\"sources\": [\n",
    "    -{\n",
    "        \"id\": \"abc-news\",\n",
    "        \"name\": \"ABC News\",\n",
    "        \"description\": \"Your trusted source for breaking news, analysis, exclusive interviews, headlines, and videos at ABCNews.com.\",\n",
    "        \"url\": \"https://abcnews.go.com\",\n",
    "        \"category\": \"general\",\n",
    "        \"language\": \"en\",\n",
    "        \"country\": \"us\"\n",
    "        },\n",
    "    -{\n",
    "        \"id\": \"abc-news-au\",\n",
    "        \"name\": \"ABC News (AU)\",\n",
    "        \"description\": \"Australia's most trusted source of local, national and world news. Comprehensive, independent, in-depth analysis, the latest business, sport, weather and more.\",\n",
    "        \"url\": \"http://www.abc.net.au/news\",\n",
    "        \"category\": \"general\",\n",
    "        \"language\": \"en\",\n",
    "        \"country\": \"au\"\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Let's start defining our class\n",
    "```Python\n",
    "class NewsConsumer:\n",
    "    NEWS_API_KEY_NAME = \"NEWS_API_KEY\"\n",
    "    BASE_URL=\"https://newsapi.org/v2/everything?\"\n",
    "\n",
    "    def __init__(self):\n",
    "        global NEWS_API_KEY_NAME\n",
    "        global BASE_URL\n",
    "        self.num_requests=0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to ask\n",
    "- What is my API limit? Can I find it in the documentation?\n",
    "- Should I stablish a limit? How to determine a limit? Can I input the limit to the API?\n",
    "- Is it going to be a flow? batches? \n",
    "\n",
    "Let's also check: https://newsapi.org/pricing\n",
    "\n",
    "Let's set up a limit of 50 pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make a request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "import os\n",
    "import requests\n",
    "import urllib.parse as urlparse\n",
    "from urllib.parse import urlencode\n",
    "class NewsConsumer:\n",
    "    \n",
    "    NEWS_API_KEY_NAME = \"NEWS_API_KEY\"\n",
    "    BASE_URL = \"https://newsapi.org/v2/everything?\"\n",
    "    REQUESTS_LIMIT = 100\n",
    "\n",
    "    def __init__(self):\n",
    "        self.num_requests=0\n",
    "        \n",
    "    def makeRequest(self, q: str, page: int, language: str = \"en\", page_size: int = 100) -> str:\n",
    "        if self.num_requests > NewsConsumer.REQUESTS_LIMIT:\n",
    "            return \"\"\n",
    "        assert page_size > 0, \"page_size can't be lesser than 0\"\n",
    "        assert page > 0, \"pagination variable can't be a negative number\"\n",
    "        url_parts = list(urlparse.urlparse(NewsConsumer.BASE_URL))\n",
    "        query = dict(urlparse.parse_qsl(url_parts[4]))\n",
    "        query.update({'q':q, 'language':language, 'pageSize':page_size, 'page':page, 'apiKey':os.getenv(NewsConsumer.NEWS_API_KEY_NAME)})\n",
    "        url_parts[4] = urlencode(query)\n",
    "        self.num_requests+=page_size\n",
    "        return requests.get(urlparse.urlunparse(url_parts))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Pickle\n",
    "Python pickle module is used for serializing and de-serializing a Python object structure. Any object in Python can be pickled so that it can be saved on disk. What pickle does is that it “serializes” the object first before writing it to file. Pickling is a way to convert a python object (list, dict, etc.) into a character stream. The idea is that this character stream contains all the information necessary to reconstruct the object in another python script.\n",
    "\n",
    "[Examples](https://www.geeksforgeeks.org/understanding-python-pickling-example/)\n",
    "```Python\n",
    "import pickle\n",
    "consumer = NewsConsumer()\n",
    "articles = consumer.makeRequest(\"vaccine\", 1)\n",
    "# more on modes: https://www.w3schools.com/python/ref_func_open.asp\n",
    "pickle.dump( articles, open( \"save.p\", \"wb\" ) )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Schema Definition\n",
    "\n",
    "- What information is relevant?\n",
    "- Pre-processing vs. Raw Information\n",
    "- What is the objective?\n",
    "- What are the restrictions? Memory restrictions, Network restrictions, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns:\n",
    "- Id: good practice to include an identifier\n",
    "- text: raw text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install library: `!pip3 install psycopg2-binary`\n",
    "\n",
    "Script\n",
    "```Python\n",
    "import psycopg2 \n",
    "conn = psycopg2.connect(\"dbname=postgres user=aaronsapa\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE documents_raw(\n",
    "   id SERIAL PRIMARY KEY,\n",
    "   text VARCHAR NOT NULL\n",
    ");\n",
    "\"\"\")\n",
    "cur.close()\n",
    "conn.commit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch insert\n",
    "\n",
    "```Python\n",
    "import psycopg2.extras\n",
    "from typing import Dict\n",
    "# Let's move this later to a util file.\n",
    "def saveTextBatch(connection, articles: Dict[str, Any])-> None:\n",
    "    with connection.cursor() as cursor:\n",
    "        iter_articles = ({'text': article['title']} for article in articles)\n",
    "        psycopg2.extras.execute_batch(cursor, \"\"\"\n",
    "        INSERT INTO documents_raw(text) VALUES (%(text)s);\n",
    "        \"\"\", iter_articles)\n",
    "        cursor.close()\n",
    "    connection.commit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it!\n",
    "\n",
    "```Python\n",
    "consumer = NewConsumer()\n",
    "articles = consumer.makeRequest(\"vaccine\", 3, page_size=10)\n",
    "connection = psycopg2.connect(\"dbname=postgres user=aaronsapa\")\n",
    "saveTextBatch(connection, articles['articles'])\n",
    "connection = psycopg2.connect(\"dbname=postgres user=aaronsapa\")\n",
    "cur = connection.cursor()\n",
    "# Never fetch all into local!\n",
    "cur.execute(\"SELECT * FROM documents_raw;\")\n",
    "cur.fetchall()\n",
    "cur.close()\n",
    "conn.close()\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def getTextDF() -> pd.DataFrame:\n",
    "    connection = psycopg2.connect(\"dbname=postgres user=aaronsapa\")\n",
    "    cur = connection.cursor()\n",
    "    cur.execute(\"SELECT * FROM documents_raw;\")\n",
    "    df = pd.DataFrame(cur.fetchall(), columns=['id','text'])\n",
    "    df.set_index(['id'], inplace=True)\n",
    "    cur.close()\n",
    "    connection.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some code refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from typing import Dict, Any, NoReturn\n",
    "import pandas as pd\n",
    "class Connector():\n",
    "    def __init__(self, db_name: str, user: str):\n",
    "        self.db_name=db_name\n",
    "        self.user=user\n",
    "        \n",
    "    def queryTransaction(self, query: str)-> NoReturn:\n",
    "        if not query:\n",
    "            return\n",
    "        connection = psycopg2.connect(f\"dbname={self.db_name} user={self.user}\")\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(query)\n",
    "            cursor.closer()\n",
    "        connection.commit()\n",
    "        connection.close()\n",
    "        \n",
    "    def saveTextBatch(self, articles: Dict[str, Any])-> NoReturn:\n",
    "        if not articles:\n",
    "            return\n",
    "        connection = psycopg2.connect(f\"dbname={self.db_name} user={self.user}\")\n",
    "        with connection.cursor() as cursor:\n",
    "            iter_articles = ({'text': article['title']} for article in articles)\n",
    "            psycopg2.extras.execute_batch(cursor, \"\"\"\n",
    "            INSERT INTO documents_raw(text) VALUES (%(text)s);\n",
    "            \"\"\", iter_articles)\n",
    "            cursor.close()\n",
    "        connection.commit()\n",
    "\n",
    "    def getTextDF(self) -> pd.DataFrame:\n",
    "        connection = psycopg2.connect(f\"dbname={self.db_name} user={self.user}\")\n",
    "        cur = connection.cursor()\n",
    "        cur.execute(\"SELECT * FROM documents_raw;\")\n",
    "        df = pd.DataFrame(cur.fetchall(), columns=['id','text'])\n",
    "        df.set_index(['id'], inplace=True)\n",
    "        cur.close()\n",
    "        connection.close()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it:\n",
    "```Python\n",
    "c = Connector('postgres', 'aaronsapa')\n",
    "df = c.getTextDF()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>What We Know About Allergic Reactions to the C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>All Adults Over 65 May Soon Be Eligible for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>FDA tells US health providers not to modify CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Resolve to Watch These 8 Shows in 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Track COVID Vaccinations With These Websites</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "id                                                    \n",
       "101  What We Know About Allergic Reactions to the C...\n",
       "102  All Adults Over 65 May Soon Be Eligible for th...\n",
       "103  FDA tells US health providers not to modify CO...\n",
       "104             Resolve to Watch These 8 Shows in 2021\n",
       "105       Track COVID Vaccinations With These Websites"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK \n",
    "*[Source](https://en.wikipedia.org/wiki/Natural_Language_Toolkit)*\n",
    "\n",
    "NLTK is intended to support research and teaching in NLP or closely related areas, including empirical linguistics, cognitive science, artificial intelligence, information retrieval, and machine learning.[7] NLTK has been used successfully as a teaching tool, as an individual study tool, and as a platform for prototyping and building research systems. There are 32 universities in the US and 25 countries using NLTK in their courses. NLTK supports classification, tokenization, stemming, tagging, parsing, and semantic reasoning functionalities.[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "!pip3 install nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "def cleanText():\n",
    "    en_stop_words = stopwords.words('english')\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    exclusion_list = '|'.join(['[^a-zA-Z]','rt', 'http', 'co', 'RT'])\n",
    "    def clean(text: str) -> str:\n",
    "        words = re.sub(exclusion_list,  ' ', text).lower().split()\n",
    "        words = [word for word in words if word not in en_stop_words]\n",
    "        words = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
    "        # list comprehension performs better in most cases than built-in func\n",
    "        # clean_words= filter(lambda word: word not in en_stop_words, words)\n",
    "        # clean_words = map(lambda word: wordnet_lemmatizer.lemmatize(word), clean_words)\n",
    "        return ' '.join(words)\n",
    "    return clean\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning text:\n",
    "```Python\n",
    "clean_text_func = cleanText()\n",
    "df['clean_text'] = df.apply(lambda row: clean_text_func(row['text']), axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>What We Know About Allergic Reactions to the C...</td>\n",
       "      <td>know allergic reaction covid vaccine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>All Adults Over 65 May Soon Be Eligible for th...</td>\n",
       "      <td>adult may soon eligible covid vaccine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>FDA tells US health providers not to modify CO...</td>\n",
       "      <td>fda tell u health provider modify covid vaccin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Resolve to Watch These 8 Shows in 2021</td>\n",
       "      <td>resolve watch show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Track COVID Vaccinations With These Websites</td>\n",
       "      <td>track covid vaccination website</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "id                                                       \n",
       "101  What We Know About Allergic Reactions to the C...   \n",
       "102  All Adults Over 65 May Soon Be Eligible for th...   \n",
       "103  FDA tells US health providers not to modify CO...   \n",
       "104             Resolve to Watch These 8 Shows in 2021   \n",
       "105       Track COVID Vaccinations With These Websites   \n",
       "\n",
       "                                            clean_text  \n",
       "id                                                      \n",
       "101               know allergic reaction covid vaccine  \n",
       "102              adult may soon eligible covid vaccine  \n",
       "103  fda tell u health provider modify covid vaccin...  \n",
       "104                                 resolve watch show  \n",
       "105                    track covid vaccination website  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def sentiment(text: str) -> int:\n",
    "    analysis = TextBlob(text)\n",
    "    polarity = analysis.sentiment.polarity\n",
    "    if polarity > 0:\n",
    "        return 1\n",
    "    elif polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df.apply(lambda row : sentiment(row['clean_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>What We Know About Allergic Reactions to the C...</td>\n",
       "      <td>know allergic reaction covid vaccine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>All Adults Over 65 May Soon Be Eligible for th...</td>\n",
       "      <td>adult may soon eligible covid vaccine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>FDA tells US health providers not to modify CO...</td>\n",
       "      <td>fda tell u health provider modify covid vaccin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Resolve to Watch These 8 Shows in 2021</td>\n",
       "      <td>resolve watch show</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Track COVID Vaccinations With These Websites</td>\n",
       "      <td>track covid vaccination website</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "id                                                       \n",
       "101  What We Know About Allergic Reactions to the C...   \n",
       "102  All Adults Over 65 May Soon Be Eligible for th...   \n",
       "103  FDA tells US health providers not to modify CO...   \n",
       "104             Resolve to Watch These 8 Shows in 2021   \n",
       "105       Track COVID Vaccinations With These Websites   \n",
       "\n",
       "                                            clean_text  sentiment  \n",
       "id                                                                 \n",
       "101               know allergic reaction covid vaccine          0  \n",
       "102              adult may soon eligible covid vaccine          1  \n",
       "103  fda tell u health provider modify covid vaccin...          0  \n",
       "104                                 resolve watch show          0  \n",
       "105                    track covid vaccination website          0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install \n",
    "`!pip install wordcloud`\n",
    "\n",
    "```Python\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "def wordCloud(words: pd.Series) -> NoReturn:\n",
    "    plt.subplots(figsize = (12,10))\n",
    "    wordcloud = WordCloud(background_color = 'white', width = 1000, height = 800).generate(' '.join(words))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "wordCloud(df[df['sentiment'] == 1]['text_clean'])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
